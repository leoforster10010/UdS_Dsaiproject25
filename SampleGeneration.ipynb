{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Constants\n",
    "Sampling_Interval = 1e-3  # Sampling interval\n",
    "Count_Samples = 1000  # Number of samples\n",
    "Sampling_Frequency = 1 / Sampling_Interval  # Sampling frequency (1MHz)\n",
    "Frequency_Resolution = Sampling_Frequency / Count_Samples  # Frequency resolution (1)\n",
    "\n",
    "# Carrier and modulation parameters\n",
    "Carrier_Frequency = 100  # Carrier frequency in MHz\n",
    "Frequency_Spacing = 1  # Frequency spacing for modulation\n",
    "Count_Frequencies = 200  # Number of modulating frequencies\n",
    "\n",
    "Time_Axis = np.arange(Count_Samples) * Sampling_Interval  # Time axis\n",
    "Frequency_Vector = np.arange(Count_Samples // 2) * Frequency_Resolution  # Frequency vector\n",
    "# AWG_Frequencies = np.array([99, 100, 101])  # frequencies in MHz\n",
    "AWG_Frequencies = np.array([95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105])  # frequencies in MHz\n",
    "AWG_Frequencies_Indices = (Count_Frequencies/2 + (AWG_Frequencies - Carrier_Frequency) / Frequency_Spacing).astype(int)  # indices in fm\n",
    "Frequencies = Carrier_Frequency + np.arange(-Count_Frequencies / 2, Count_Frequencies / 2 + 1) * Frequency_Spacing\n"
   ],
   "id": "51107b34b23ebaa3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_awg_time_signal(time_axis, awg_frequencies_indices, frequencies, awg_freqs_real, awg_freqs_imag):\n",
    "    awg_time_signal = np.zeros_like(time_axis)\n",
    "    for index in awg_frequencies_indices:\n",
    "        awg_time_signal += awg_freqs_real[index] * np.cos(2 * np.pi * frequencies[index] * time_axis) - awg_freqs_imag[index] * np.sin(2 * np.pi * frequencies[index] * time_axis)\n",
    "\n",
    "    return awg_time_signal\n",
    "\n",
    "def simulate_aom(awg_time_signal):\n",
    "    return np.sin(2 * np.pi * awg_time_signal)\n",
    "\n",
    "def fft(time_signal):\n",
    "    spectrum = np.fft.fft(time_signal) / (Count_Samples / 2)\n",
    "    real_part = np.real(spectrum[:Count_Samples // 2])\n",
    "    imag_part = np.imag(spectrum[:Count_Samples // 2])\n",
    "    return real_part, imag_part\n",
    "\n",
    "def mask_fft(real_part, imag_part):\n",
    "    f_min = 50  # MHz\n",
    "    f_max = 150  # MHz\n",
    "    mask = (Frequency_Vector >= f_min) & (Frequency_Vector <= f_max)\n",
    "    real_part_masked = real_part[mask]\n",
    "    imag_part_masked = imag_part[mask]\n",
    "    return real_part_masked, imag_part_masked\n",
    "\n",
    "def sample_awg_input():\n",
    "    # vec = np.random.uniform(-0.5, 0.5, 6)\n",
    "    vec = np.random.uniform(-0.5, 0.5, 22)\n",
    "    vec =  0.1 * vec / np.linalg.norm(vec)\n",
    "    # awg_input_a = vec[:3]\n",
    "    # awg_input_b = vec[3:]\n",
    "    awg_input_a = vec[:11]\n",
    "    awg_input_b = vec[11:]\n",
    "    return awg_input_a, awg_input_b\n",
    "\n",
    "def generate_input():\n",
    "    (awg_input_a, awg_input_b) = sample_awg_input()\n",
    "    return awg_input_a, awg_input_b\n",
    "\n",
    "def generate_output(awg_input_a, awg_input_b):\n",
    "    an = np.zeros_like(Frequencies)\n",
    "    bn = np.zeros_like(Frequencies)\n",
    "\n",
    "    an[AWG_Frequencies_Indices] = awg_input_a\n",
    "    bn[AWG_Frequencies_Indices] = awg_input_b\n",
    "\n",
    "    awg_time_signal = generate_awg_time_signal(Time_Axis, AWG_Frequencies_Indices, Frequencies, an, bn)\n",
    "    aom_time_signal = simulate_aom(awg_time_signal)\n",
    "\n",
    "    (real_part, imag_part) = fft(aom_time_signal)\n",
    "    (real_part_masked, imag_part_masked) = mask_fft(real_part, imag_part)\n",
    "\n",
    "    return real_part_masked, imag_part_masked\n",
    "\n",
    "def generate_samples(number_samples = 10000):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for _ in range(number_samples):\n",
    "        (awg_input_a, awg_input_b) = generate_input()\n",
    "        inputs.append(np.concatenate((awg_input_a, awg_input_b)))\n",
    "\n",
    "        (real_part_masked, imag_part_masked) = generate_output(awg_input_a, awg_input_b)\n",
    "        outputs.append(np.concatenate((real_part_masked, imag_part_masked)))\n",
    "\n",
    "    return np.array(inputs), np.array(outputs)"
   ],
   "id": "baf4849a3e5dc067",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Y, X = generate_samples(10000)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# Dataset\n",
    "class SpectrumDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.Y[i]\n",
    "\n",
    "train_loader = DataLoader(SpectrumDataset(X_train, Y_train), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(SpectrumDataset(X_val, Y_val), batch_size=64)\n",
    "\n",
    "# Model\n",
    "class SpectrumMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(202, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            # nn.Linear(64, 6)\n",
    "            nn.Linear(64, 22)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class SpectrumCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 22)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        return self.net(x)\n",
    "\n",
    "# Train function\n",
    "def train_model(model, train_loader, val_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "    loss_fn = nn.L1Loss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(40):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                preds = model(xb)\n",
    "                val_loss += loss_fn(preds, yb).item() * xb.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:2d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def predict_output(model, real_part_masked, imag_part_masked):\n",
    "    input_vector = np.concatenate((real_part_masked, imag_part_masked))\n",
    "    input_vector = input_vector.reshape(1, -1)  # reshape to (1, length)\n",
    "    input_tensor = torch.tensor(input_vector, dtype=torch.float32)\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predicted = model(input_tensor).numpy().flatten()\n",
    "    predicted_a = predicted[:11]\n",
    "    predicted_b = predicted[11:]\n",
    "    return predicted_a, predicted_b\n",
    "\n",
    "model = SpectrumMLP()\n",
    "train_model(model, train_loader, val_loader)"
   ],
   "id": "8ba823b7a3d50c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "awg_input_a = [0, 0, 0, 0, 0.025, -0.05, 0.025, 0, 0, 0, 0]\n",
    "awg_input_b = [0, 0, 0, 0, -0.025, 0.05, -0.025, 0, 0, 0, 0]\n",
    "\n",
    "# (awg_input_a, awg_input_b) = generate_input()\n",
    "\n",
    "(real_part_masked, imag_part_masked) = generate_output(awg_input_a, awg_input_b)\n",
    "\n",
    "(awg_input_a_pred, awg_input_b_pred) = predict_output(model, real_part_masked, imag_part_masked)\n",
    "\n",
    "(real_part_masked_pred, imag_part_masked_pred) = generate_output(awg_input_a_pred, awg_input_b_pred)"
   ],
   "id": "167b92736e721f48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "awg_input_real_stem = plt.stem(awg_input_a, label='Real', linefmt='b-', markerfmt='bo', basefmt=\" \")\n",
    "awg_input_imag_stem = plt.stem(awg_input_b, label='Imag', linefmt='r-', markerfmt='ro', basefmt=\" \")\n",
    "\n",
    "plt.title(\"AWG Input Spectrum\")\n",
    "plt.xlabel(\"Frequency (MHz)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "aom_out_real_stem = plt.stem(real_part_masked, label='Real', linefmt='b-', markerfmt='bo', basefmt=\" \")\n",
    "aom_out_imag_stem = plt.stem(imag_part_masked, label='Imag', linefmt='r-', markerfmt='ro', basefmt=\" \")\n",
    "\n",
    "plt.title(\"AOM Output Spectrum\")\n",
    "plt.xlabel(\"Frequency (MHz)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlim([40, 60])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "awg_input_real_stem_pred = plt.stem(awg_input_a_pred, label='Real', linefmt='b-', markerfmt='bo', basefmt=\" \")\n",
    "awg_input_imag_stem_pred = plt.stem(awg_input_b_pred, label='Imag', linefmt='r-', markerfmt='ro', basefmt=\" \")\n",
    "\n",
    "plt.title(\"Predicted AWG Input Spectrum\")\n",
    "plt.xlabel(\"Frequency (MHz)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "aom_out_real_stem_pred = plt.stem(real_part_masked_pred, label='Real', linefmt='b-', markerfmt='bo', basefmt=\" \")\n",
    "aom_out_imag_stem_pred = plt.stem(imag_part_masked_pred, label='Imag', linefmt='r-', markerfmt='ro', basefmt=\" \")\n",
    "\n",
    "plt.title(\"Predicted AOM Output Spectrum\")\n",
    "plt.xlabel(\"Frequency (MHz)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlim([40, 60])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "67f2cfa8e52ff90b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "202e3c341bff42ff",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
