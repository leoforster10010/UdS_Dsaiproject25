{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Constants\n",
    "Sampling_Interval = 1e-3  # Sampling interval\n",
    "Count_Samples = 1000  # Number of samples\n",
    "Sampling_Frequency = 1 / Sampling_Interval  # Sampling frequency (1MHz)\n",
    "Frequency_Resolution = Sampling_Frequency / Count_Samples  # Frequency resolution (1)\n",
    "Count_Input_Frequencies = 22\n",
    "Count_Output_Frequencies = 202\n",
    "\n",
    "# Carrier and modulation parameters\n",
    "Carrier_Frequency = 100  # Carrier frequency in MHz\n",
    "Frequency_Spacing = 1  # Frequency spacing for modulation\n",
    "Count_Frequencies = 200  # Number of modulating frequencies\n",
    "\n",
    "Time_Axis = np.arange(Count_Samples) * Sampling_Interval  # Time axis\n",
    "Frequency_Vector = np.arange(Count_Samples // 2) * Frequency_Resolution  # Frequency vector\n",
    "# AWG_Frequencies = np.array([99, 100, 101])  # frequencies in MHz\n",
    "AWG_Frequencies = np.array([95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105])  # frequencies in MHz\n",
    "AWG_Frequencies_Indices = (Count_Frequencies/2 + (AWG_Frequencies - Carrier_Frequency) / Frequency_Spacing).astype(int)  # indices in fm\n",
    "Frequencies = Carrier_Frequency + np.arange(-Count_Frequencies / 2, Count_Frequencies / 2 + 1) * Frequency_Spacing\n",
    "\n",
    "seed = 42"
   ],
   "id": "51107b34b23ebaa3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_awg_time_signal(time_axis, awg_frequencies_indices, frequencies, awg_freqs_real, awg_freqs_imag):\n",
    "    awg_time_signal = np.zeros_like(time_axis)\n",
    "    for index in awg_frequencies_indices:\n",
    "        awg_time_signal += awg_freqs_real[index] * np.cos(2 * np.pi * frequencies[index] * time_axis) - awg_freqs_imag[index] * np.sin(2 * np.pi * frequencies[index] * time_axis)\n",
    "\n",
    "    return awg_time_signal\n",
    "\n",
    "def simulate_aom(awg_time_signal):\n",
    "    return np.sin(2 * np.pi * awg_time_signal)\n",
    "\n",
    "def fft(time_signal):\n",
    "    spectrum = np.fft.fft(time_signal) / (Count_Samples / 2)\n",
    "    real_part = np.real(spectrum[:Count_Samples // 2])\n",
    "    imag_part = np.imag(spectrum[:Count_Samples // 2])\n",
    "    return real_part, imag_part\n",
    "\n",
    "def mask_fft(real_part, imag_part):\n",
    "    f_min = 50  # MHz\n",
    "    f_max = 150  # MHz\n",
    "    mask = (Frequency_Vector >= f_min) & (Frequency_Vector <= f_max)\n",
    "    real_part_masked = real_part[mask]\n",
    "    imag_part_masked = imag_part[mask]\n",
    "    return real_part_masked, imag_part_masked\n",
    "\n",
    "def sample_awg_input():\n",
    "    vec = np.random.uniform(-0.5, 0.5, Count_Input_Frequencies)\n",
    "    vec =  0.1 * vec / np.linalg.norm(vec)\n",
    "    awg_input_a = vec[:(Count_Input_Frequencies // 2)]\n",
    "    awg_input_b = vec[(Count_Input_Frequencies // 2):]\n",
    "    return awg_input_a, awg_input_b\n",
    "\n",
    "def generate_input():\n",
    "    (awg_input_a, awg_input_b) = sample_awg_input()\n",
    "    return awg_input_a, awg_input_b\n",
    "\n",
    "def generate_output(awg_input_a, awg_input_b):\n",
    "    an = np.zeros_like(Frequencies)\n",
    "    bn = np.zeros_like(Frequencies)\n",
    "\n",
    "    an[AWG_Frequencies_Indices] = awg_input_a\n",
    "    bn[AWG_Frequencies_Indices] = awg_input_b\n",
    "\n",
    "    awg_time_signal = generate_awg_time_signal(Time_Axis, AWG_Frequencies_Indices, Frequencies, an, bn)\n",
    "    aom_time_signal = simulate_aom(awg_time_signal)\n",
    "\n",
    "    (real_part, imag_part) = fft(aom_time_signal)\n",
    "    (real_part_masked, imag_part_masked) = mask_fft(real_part, imag_part)\n",
    "\n",
    "    return real_part_masked, imag_part_masked\n",
    "\n",
    "def generate_samples(number_samples = 10000):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for _ in range(number_samples):\n",
    "        (awg_input_a, awg_input_b) = generate_input()\n",
    "        inputs.append(np.concatenate((awg_input_a, awg_input_b)))\n",
    "\n",
    "        (real_part_masked, imag_part_masked) = generate_output(awg_input_a, awg_input_b)\n",
    "        outputs.append(np.concatenate((real_part_masked, imag_part_masked)))\n",
    "\n",
    "    return np.array(inputs), np.array(outputs)"
   ],
   "id": "baf4849a3e5dc067",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset\n",
    "class SpectrumDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.Y[i]\n",
    "\n",
    "\n",
    "# Model\n",
    "class SpectrumMLP(nn.Module):\n",
    "    def __init__(self, layer_1_size = 256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(Count_Output_Frequencies, layer_1_size),\n",
    "            nn.BatchNorm1d(layer_1_size),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(layer_1_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            # nn.Linear(64, 6)\n",
    "            nn.Linear(64, Count_Input_Frequencies)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class SpectrumCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, Count_Output_Frequencies)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        return self.net(x)\n",
    "\n",
    "# Train function\n",
    "def train_model(model, train_loader, val_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "    loss_fn = nn.L1Loss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(40):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                preds = model(xb)\n",
    "                val_loss += loss_fn(preds, yb).item() * xb.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:2d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def predict_output(model, real_part_masked, imag_part_masked):\n",
    "    input_vector = np.concatenate((real_part_masked, imag_part_masked))\n",
    "    input_vector = input_vector.reshape(1, -1)  # reshape to (1, length)\n",
    "    input_tensor = torch.tensor(input_vector, dtype=torch.float32)\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predicted = model(input_tensor).numpy().flatten()\n",
    "    predicted_a = predicted[:(Count_Input_Frequencies // 2)]\n",
    "    predicted_b = predicted[(Count_Input_Frequencies // 2):]\n",
    "    return predicted_a, predicted_b\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def evaluate_layer_sizes(layer_sizes):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for size in layer_sizes:\n",
    "        set_seed(seed)\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        Y, X = generate_samples(10000)\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2)\n",
    "        train_loader = DataLoader(SpectrumDataset(X_train, Y_train), batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(SpectrumDataset(X_val, Y_val), batch_size=64)\n",
    "        model = SpectrumMLP(size)\n",
    "        train_loss, val_loss = train_model(model, train_loader, val_loader)\n",
    "        train_losses.append(train_loss[-1])\n",
    "        val_losses.append(val_loss[-1])\n",
    "\n",
    "    return train_losses, val_losses"
   ],
   "id": "5071bb3b13e89aa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "set_seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "Y, X = generate_samples(10000)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "train_loader = DataLoader(SpectrumDataset(X_train, Y_train), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(SpectrumDataset(X_val, Y_val), batch_size=64)\n",
    "\n",
    "model = SpectrumMLP(1024)\n",
    "(train_losses, val_losses) = train_model(model, train_loader, val_loader)"
   ],
   "id": "8ba823b7a3d50c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "layer_sizes = [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
    "(train_losses, val_losses) = evaluate_layer_sizes(layer_sizes)"
   ],
   "id": "17cc6bac1c4b700b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(layer_sizes, train_losses, marker='o', label='Train Loss')\n",
    "plt.plot(layer_sizes, val_losses, marker='o', label='Validation Loss')\n",
    "plt.xlabel('Layer Size')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Layer Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "ee3693de4025bb34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "awg_input_a = [0, 0, 0, 0, 0.05, -0.05, 0.025, 0, 0, 0, 0]\n",
    "awg_input_b = [0, 0, 0, 0, -0.025, 0.05, -0.05, 0, 0, 0, 0]\n",
    "\n",
    "# awg_input_a = [0, 0, 0, 0, 0.1, -0.5, 0.2, 0, 0, 0, 0]\n",
    "# awg_input_b = [0, 0, 0, 0, -0.2, 0.5, -0.1, 0, 0, 0, 0]\n",
    "\n",
    "# (awg_input_a, awg_input_b) = generate_input()\n",
    "\n",
    "(real_part_masked, imag_part_masked) = generate_output(awg_input_a, awg_input_b)\n",
    "\n",
    "(awg_input_a_pred, awg_input_b_pred) = predict_output(model, real_part_masked, imag_part_masked)\n",
    "\n",
    "(real_part_masked_pred, imag_part_masked_pred) = generate_output(awg_input_a_pred, awg_input_b_pred)"
   ],
   "id": "167b92736e721f48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_vals = np.arange(len(real_part_masked)) + 50\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "awg_input_real_stem = plt.stem(awg_input_a, label='Real', linefmt='b-', markerfmt='bo', basefmt=\" \")\n",
    "awg_input_imag_stem = plt.stem(awg_input_b, label='Imag', linefmt='r-', markerfmt='ro', basefmt=\" \")\n",
    "\n",
    "plt.title(\"AWG Input Spectrum\", fontsize=20)\n",
    "plt.xlabel(\"Frequency (MHz)\", fontsize=20)\n",
    "plt.ylabel(\"Amplitude\", fontsize=20)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "aom_out_real_stem = plt.stem(x_vals, real_part_masked, label='Real', linefmt='b-', markerfmt='bo', basefmt=\" \")\n",
    "aom_out_imag_stem = plt.stem(x_vals, imag_part_masked, label='Imag', linefmt='r-', markerfmt='ro', basefmt=\" \")\n",
    "\n",
    "plt.title(\"AOM Output Spectrum\", fontsize=20)\n",
    "plt.xlabel(\"Frequency (MHz)\", fontsize=20)\n",
    "plt.ylabel(\"Amplitude\", fontsize=20)\n",
    "plt.xlim([80, 120])\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "awg_input_real_stem_pred = plt.stem(awg_input_a_pred, label='Real', linefmt='b-', markerfmt='bo', basefmt=\" \")\n",
    "awg_input_imag_stem_pred = plt.stem(awg_input_b_pred, label='Imag', linefmt='r-', markerfmt='ro', basefmt=\" \")\n",
    "\n",
    "plt.title(\"Predicted AWG Input Spectrum\", fontsize=16)\n",
    "plt.xlabel(\"Frequency (MHz)\", fontsize=14)\n",
    "plt.ylabel(\"Amplitude\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "aom_out_real_stem_pred = plt.stem(x_vals, real_part_masked_pred, label='Real', linefmt='b-', markerfmt='bo', basefmt=\" \")\n",
    "aom_out_imag_stem_pred = plt.stem(x_vals, imag_part_masked_pred, label='Imag', linefmt='r-', markerfmt='ro', basefmt=\" \")\n",
    "\n",
    "plt.title(\"Predicted AOM Output Spectrum\", fontsize=16)\n",
    "plt.xlabel(\"Frequency (MHz)\", fontsize=14)\n",
    "plt.ylabel(\"Amplitude\", fontsize=14)\n",
    "plt.xlim([80, 120])\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n"
   ],
   "id": "67f2cfa8e52ff90b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "202e3c341bff42ff",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
